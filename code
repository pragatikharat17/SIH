import cv2
import os
import numpy as np
import mediapipe as mp
import tensorflow as tf  # Assuming you use TensorFlow for model loading

# Initialize MediaPipe modules
mp_pose = mp.solutions.pose
mp_face_mesh = mp.solutions.face_mesh
mp_drawing = mp.solutions.drawing_utils

# Load trained model (e.g., a CNN) for NMF recognition
model = tf.keras.models.load_model('/Users/pragatik/Desktop/pandas/sih/Dataset/A')  # Update with your model path

# Function to preprocess image for model prediction
def preprocess_image(image):
    image_resized = cv2.resize(image, (224, 224))  # Resize to match model input size
    image_normalized = image_resized / 255.0  # Normalize pixel values
    return np.expand_dims(image_normalized, axis=0)  # Add batch dimension

# Load dataset of images (if needed for reference or comparison)
dataset_path = "path/to/your/dataset"  # Update this path
dataset = {}
for filename in os.listdir(dataset_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):
        sign_name = filename.split('.')[0]  # Extract sign name from filename
        img = cv2.imread(os.path.join(dataset_path, filename))
        if img is not None:
            dataset[sign_name] = img  # Store image in dataset dictionary

# Image dimensions
IMAGE_HEIGHT, IMAGE_WIDTH = 720, 1280

# Capture video
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMAGE_WIDTH)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMAGE_HEIGHT)

# Flag to track previous face recognition status
face_recognized = False
recognized_sign = ""

# Setup Pose and Face Mesh models
with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \
     mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:
    
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            continue

        frame = cv2.flip(frame, 1)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Pose estimation
        pose_results = pose.process(frame_rgb)

        # Face landmark detection
        face_results = face_mesh.process(frame_rgb)

        # Draw pose landmarks
        if pose_results.pose_landmarks:
            mp_drawing.draw_landmarks(
                frame, 
                pose_results.pose_landmarks, 
                mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=4, circle_radius=4),  
                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=4, circle_radius=2))

        # Check if face landmarks are detected
        if face_results.multi_face_landmarks:
            if not face_recognized:  # If the face was not recognized before
                face_recognized = True
                print("Face Recognized!")  # Print only once when recognized
            # Draw the face landmarks
            for face_landmarks in face_results.multi_face_landmarks:
                mp_drawing.draw_landmarks(
                    image=frame,
                    landmark_list=face_landmarks,
                    connections=mp_face_mesh.FACEMESH_CONTOURS,
                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2),
                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))

            # Extract face area for model prediction (optional preprocessing)
            # You can modify this section to extract relevant NMF regions based on your model's input
            face_roi = frame_rgb  # Replace this with the actual region of interest
            preprocessed_face = preprocess_image(face_roi)

            # Predict using the trained model
            predictions = model.predict(preprocessed_face)
            predicted_sign = np.argmax(predictions, axis=1)  # Assuming classification model

            # Convert prediction index to label (this depends on how your model was trained)
            recognized_sign = "SignLabel"  # Map predicted index to label, e.g., {0: 'Hello', 1: 'Thank You'}

            # Show the recognized sign on the frame
            if recognized_sign in dataset:
                sign_image = dataset[recognized_sign]
                sign_image_resized = cv2.resize(sign_image, (200, 200))  # Resize to fit
                frame[50:250, 50:250] = sign_image_resized  # Place image on the frame
                cv2.putText(frame, recognized_sign, (50, 300), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

        else:
            if face_recognized:  # If the face was recognized previously but now not
                face_recognized = False
                print("Face Not Recognized!")  # Print only once when recognition stops
            
            # Show text message when face is not recognized
            cv2.putText(frame, "Face Not Recognized", (50, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)

        # Display the output frame
        cv2.imshow('NMF Recognition - Pose and Face', frame)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyAllWindows()

